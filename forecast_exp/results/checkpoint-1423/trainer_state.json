{
  "best_metric": 10.4756,
  "best_model_checkpoint": "./results/checkpoint-1423",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1423,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.007027406886858749,
      "grad_norm": 1.6860004663467407,
      "learning_rate": 9.993675333801827e-05,
      "loss": -1.2921,
      "step": 10
    },
    {
      "epoch": 0.014054813773717497,
      "grad_norm": 1.5223720073699951,
      "learning_rate": 9.98664792691497e-05,
      "loss": -1.3807,
      "step": 20
    },
    {
      "epoch": 0.02108222066057625,
      "grad_norm": 0.8838928937911987,
      "learning_rate": 9.97962052002811e-05,
      "loss": -1.4051,
      "step": 30
    },
    {
      "epoch": 0.028109627547434995,
      "grad_norm": 0.9422695636749268,
      "learning_rate": 9.97259311314125e-05,
      "loss": -1.4302,
      "step": 40
    },
    {
      "epoch": 0.035137034434293744,
      "grad_norm": 2.1020593643188477,
      "learning_rate": 9.965565706254392e-05,
      "loss": -1.4926,
      "step": 50
    },
    {
      "epoch": 0.0421644413211525,
      "grad_norm": 1.212904453277588,
      "learning_rate": 9.958538299367534e-05,
      "loss": -1.5129,
      "step": 60
    },
    {
      "epoch": 0.049191848208011243,
      "grad_norm": 1.2417880296707153,
      "learning_rate": 9.951510892480675e-05,
      "loss": -1.5735,
      "step": 70
    },
    {
      "epoch": 0.05621925509486999,
      "grad_norm": 1.4859538078308105,
      "learning_rate": 9.944483485593816e-05,
      "loss": -1.657,
      "step": 80
    },
    {
      "epoch": 0.06324666198172874,
      "grad_norm": 2.792626142501831,
      "learning_rate": 9.937456078706959e-05,
      "loss": -1.772,
      "step": 90
    },
    {
      "epoch": 0.07027406886858749,
      "grad_norm": 4.062569618225098,
      "learning_rate": 9.930428671820099e-05,
      "loss": -2.0051,
      "step": 100
    },
    {
      "epoch": 0.07730147575544624,
      "grad_norm": 10.54062557220459,
      "learning_rate": 9.924104005621925e-05,
      "loss": -2.3975,
      "step": 110
    },
    {
      "epoch": 0.084328882642305,
      "grad_norm": Infinity,
      "learning_rate": 9.918482080112439e-05,
      "loss": -2.6963,
      "step": 120
    },
    {
      "epoch": 0.09135628952916373,
      "grad_norm": 11.13524341583252,
      "learning_rate": 9.91145467322558e-05,
      "loss": -2.8551,
      "step": 130
    },
    {
      "epoch": 0.09838369641602249,
      "grad_norm": 27.765460968017578,
      "learning_rate": 9.904427266338721e-05,
      "loss": -3.1458,
      "step": 140
    },
    {
      "epoch": 0.10541110330288124,
      "grad_norm": 50.406158447265625,
      "learning_rate": 9.897399859451863e-05,
      "loss": -3.0714,
      "step": 150
    },
    {
      "epoch": 0.11243851018973998,
      "grad_norm": 7.153792858123779,
      "learning_rate": 9.890372452565004e-05,
      "loss": -3.0842,
      "step": 160
    },
    {
      "epoch": 0.11946591707659873,
      "grad_norm": 19.641448974609375,
      "learning_rate": 9.883345045678145e-05,
      "loss": -3.6879,
      "step": 170
    },
    {
      "epoch": 0.12649332396345747,
      "grad_norm": Infinity,
      "learning_rate": 9.877020379479973e-05,
      "loss": -3.393,
      "step": 180
    },
    {
      "epoch": 0.13352073085031624,
      "grad_norm": 50.81373596191406,
      "learning_rate": 9.869992972593114e-05,
      "loss": -3.653,
      "step": 190
    },
    {
      "epoch": 0.14054813773717498,
      "grad_norm": 45.54872512817383,
      "learning_rate": 9.862965565706254e-05,
      "loss": -3.8452,
      "step": 200
    },
    {
      "epoch": 0.14757554462403374,
      "grad_norm": 20.347394943237305,
      "learning_rate": 9.855938158819396e-05,
      "loss": -4.0533,
      "step": 210
    },
    {
      "epoch": 0.15460295151089248,
      "grad_norm": 25.921110153198242,
      "learning_rate": 9.848910751932538e-05,
      "loss": -4.2427,
      "step": 220
    },
    {
      "epoch": 0.16163035839775122,
      "grad_norm": 13.012264251708984,
      "learning_rate": 9.841883345045678e-05,
      "loss": -4.3694,
      "step": 230
    },
    {
      "epoch": 0.16865776528461,
      "grad_norm": 60.69106674194336,
      "learning_rate": 9.83485593815882e-05,
      "loss": -4.5216,
      "step": 240
    },
    {
      "epoch": 0.17568517217146873,
      "grad_norm": 18.223241806030273,
      "learning_rate": 9.827828531271961e-05,
      "loss": -4.592,
      "step": 250
    },
    {
      "epoch": 0.18271257905832747,
      "grad_norm": 16.20248794555664,
      "learning_rate": 9.820801124385103e-05,
      "loss": -4.5475,
      "step": 260
    },
    {
      "epoch": 0.18973998594518623,
      "grad_norm": 54.024654388427734,
      "learning_rate": 9.813773717498243e-05,
      "loss": -4.8331,
      "step": 270
    },
    {
      "epoch": 0.19676739283204497,
      "grad_norm": 21.992366790771484,
      "learning_rate": 9.806746310611385e-05,
      "loss": -4.6675,
      "step": 280
    },
    {
      "epoch": 0.2037947997189037,
      "grad_norm": Infinity,
      "learning_rate": 9.800421644413213e-05,
      "loss": -4.5446,
      "step": 290
    },
    {
      "epoch": 0.21082220660576248,
      "grad_norm": 58.36254119873047,
      "learning_rate": 9.793394237526353e-05,
      "loss": -4.593,
      "step": 300
    },
    {
      "epoch": 0.21784961349262122,
      "grad_norm": 33.2662467956543,
      "learning_rate": 9.786366830639495e-05,
      "loss": -4.8962,
      "step": 310
    },
    {
      "epoch": 0.22487702037947996,
      "grad_norm": 43.39387512207031,
      "learning_rate": 9.779339423752636e-05,
      "loss": -4.9067,
      "step": 320
    },
    {
      "epoch": 0.23190442726633873,
      "grad_norm": 31.868099212646484,
      "learning_rate": 9.772312016865777e-05,
      "loss": -4.8554,
      "step": 330
    },
    {
      "epoch": 0.23893183415319746,
      "grad_norm": 32.99828338623047,
      "learning_rate": 9.765284609978918e-05,
      "loss": -4.7624,
      "step": 340
    },
    {
      "epoch": 0.24595924104005623,
      "grad_norm": 22.345361709594727,
      "learning_rate": 9.75825720309206e-05,
      "loss": -4.3312,
      "step": 350
    },
    {
      "epoch": 0.25298664792691494,
      "grad_norm": 19.150009155273438,
      "learning_rate": 9.751229796205202e-05,
      "loss": -5.3253,
      "step": 360
    },
    {
      "epoch": 0.2600140548137737,
      "grad_norm": 73.74205017089844,
      "learning_rate": 9.744202389318342e-05,
      "loss": -4.8292,
      "step": 370
    },
    {
      "epoch": 0.2670414617006325,
      "grad_norm": 66.38163757324219,
      "learning_rate": 9.737174982431483e-05,
      "loss": -5.1897,
      "step": 380
    },
    {
      "epoch": 0.27406886858749124,
      "grad_norm": 49.51173782348633,
      "learning_rate": 9.730147575544625e-05,
      "loss": -5.6284,
      "step": 390
    },
    {
      "epoch": 0.28109627547434995,
      "grad_norm": 35.72504806518555,
      "learning_rate": 9.723120168657765e-05,
      "loss": -5.4332,
      "step": 400
    },
    {
      "epoch": 0.2881236823612087,
      "grad_norm": 35.065677642822266,
      "learning_rate": 9.716092761770907e-05,
      "loss": -5.3912,
      "step": 410
    },
    {
      "epoch": 0.2951510892480675,
      "grad_norm": 64.38773345947266,
      "learning_rate": 9.709065354884049e-05,
      "loss": -5.3189,
      "step": 420
    },
    {
      "epoch": 0.3021784961349262,
      "grad_norm": 48.378482818603516,
      "learning_rate": 9.702037947997189e-05,
      "loss": -5.4603,
      "step": 430
    },
    {
      "epoch": 0.30920590302178497,
      "grad_norm": 23.19247055053711,
      "learning_rate": 9.69501054111033e-05,
      "loss": -5.4158,
      "step": 440
    },
    {
      "epoch": 0.31623330990864373,
      "grad_norm": 64.5969467163086,
      "learning_rate": 9.687983134223472e-05,
      "loss": -5.1215,
      "step": 450
    },
    {
      "epoch": 0.32326071679550245,
      "grad_norm": 44.53466033935547,
      "learning_rate": 9.680955727336614e-05,
      "loss": -5.9027,
      "step": 460
    },
    {
      "epoch": 0.3302881236823612,
      "grad_norm": 30.518274307250977,
      "learning_rate": 9.673928320449754e-05,
      "loss": -5.459,
      "step": 470
    },
    {
      "epoch": 0.33731553056922,
      "grad_norm": 101.69618225097656,
      "learning_rate": 9.666900913562896e-05,
      "loss": -5.2915,
      "step": 480
    },
    {
      "epoch": 0.3443429374560787,
      "grad_norm": 71.34317016601562,
      "learning_rate": 9.659873506676038e-05,
      "loss": -4.9095,
      "step": 490
    },
    {
      "epoch": 0.35137034434293746,
      "grad_norm": 84.34651184082031,
      "learning_rate": 9.652846099789178e-05,
      "loss": -5.6687,
      "step": 500
    },
    {
      "epoch": 0.3583977512297962,
      "grad_norm": 42.30650329589844,
      "learning_rate": 9.64581869290232e-05,
      "loss": -5.7226,
      "step": 510
    },
    {
      "epoch": 0.36542515811665494,
      "grad_norm": 79.91998291015625,
      "learning_rate": 9.638791286015461e-05,
      "loss": -5.7669,
      "step": 520
    },
    {
      "epoch": 0.3724525650035137,
      "grad_norm": 63.55778503417969,
      "learning_rate": 9.631763879128603e-05,
      "loss": -5.9739,
      "step": 530
    },
    {
      "epoch": 0.37947997189037247,
      "grad_norm": 23.731168746948242,
      "learning_rate": 9.624736472241743e-05,
      "loss": -5.8008,
      "step": 540
    },
    {
      "epoch": 0.3865073787772312,
      "grad_norm": 58.560874938964844,
      "learning_rate": 9.617709065354885e-05,
      "loss": -5.2713,
      "step": 550
    },
    {
      "epoch": 0.39353478566408995,
      "grad_norm": 48.000518798828125,
      "learning_rate": 9.610681658468026e-05,
      "loss": -5.8234,
      "step": 560
    },
    {
      "epoch": 0.4005621925509487,
      "grad_norm": 64.36412048339844,
      "learning_rate": 9.603654251581167e-05,
      "loss": -5.5284,
      "step": 570
    },
    {
      "epoch": 0.4075895994378074,
      "grad_norm": 53.271366119384766,
      "learning_rate": 9.596626844694308e-05,
      "loss": -5.5427,
      "step": 580
    },
    {
      "epoch": 0.4146170063246662,
      "grad_norm": 79.79280090332031,
      "learning_rate": 9.58959943780745e-05,
      "loss": -5.9536,
      "step": 590
    },
    {
      "epoch": 0.42164441321152496,
      "grad_norm": 150.04550170898438,
      "learning_rate": 9.582572030920592e-05,
      "loss": -5.8571,
      "step": 600
    },
    {
      "epoch": 0.42867182009838367,
      "grad_norm": 93.87496948242188,
      "learning_rate": 9.575544624033732e-05,
      "loss": -6.0092,
      "step": 610
    },
    {
      "epoch": 0.43569922698524244,
      "grad_norm": 117.1666259765625,
      "learning_rate": 9.568517217146874e-05,
      "loss": -6.087,
      "step": 620
    },
    {
      "epoch": 0.4427266338721012,
      "grad_norm": 50.84917449951172,
      "learning_rate": 9.561489810260015e-05,
      "loss": -6.1588,
      "step": 630
    },
    {
      "epoch": 0.4497540407589599,
      "grad_norm": 51.93496322631836,
      "learning_rate": 9.554462403373155e-05,
      "loss": -6.3485,
      "step": 640
    },
    {
      "epoch": 0.4567814476458187,
      "grad_norm": 32.84553527832031,
      "learning_rate": 9.547434996486297e-05,
      "loss": -6.2964,
      "step": 650
    },
    {
      "epoch": 0.46380885453267745,
      "grad_norm": 60.058799743652344,
      "learning_rate": 9.540407589599439e-05,
      "loss": -6.2155,
      "step": 660
    },
    {
      "epoch": 0.4708362614195362,
      "grad_norm": 32.49545669555664,
      "learning_rate": 9.533380182712579e-05,
      "loss": -6.1921,
      "step": 670
    },
    {
      "epoch": 0.47786366830639493,
      "grad_norm": 27.035213470458984,
      "learning_rate": 9.526352775825721e-05,
      "loss": -6.3931,
      "step": 680
    },
    {
      "epoch": 0.4848910751932537,
      "grad_norm": 81.44160461425781,
      "learning_rate": 9.519325368938862e-05,
      "loss": -6.3278,
      "step": 690
    },
    {
      "epoch": 0.49191848208011246,
      "grad_norm": 158.89794921875,
      "learning_rate": 9.512297962052004e-05,
      "loss": -6.2272,
      "step": 700
    },
    {
      "epoch": 0.4989458889669712,
      "grad_norm": 130.32418823242188,
      "learning_rate": 9.505270555165144e-05,
      "loss": -6.2297,
      "step": 710
    },
    {
      "epoch": 0.5059732958538299,
      "grad_norm": 74.09990692138672,
      "learning_rate": 9.498243148278286e-05,
      "loss": -6.4421,
      "step": 720
    },
    {
      "epoch": 0.5130007027406887,
      "grad_norm": 49.37168884277344,
      "learning_rate": 9.491215741391428e-05,
      "loss": -6.165,
      "step": 730
    },
    {
      "epoch": 0.5200281096275474,
      "grad_norm": 75.5392074584961,
      "learning_rate": 9.484188334504568e-05,
      "loss": -6.5732,
      "step": 740
    },
    {
      "epoch": 0.5270555165144062,
      "grad_norm": 45.11758041381836,
      "learning_rate": 9.47716092761771e-05,
      "loss": -6.3273,
      "step": 750
    },
    {
      "epoch": 0.534082923401265,
      "grad_norm": 95.66844940185547,
      "learning_rate": 9.470133520730851e-05,
      "loss": -6.5303,
      "step": 760
    },
    {
      "epoch": 0.5411103302881237,
      "grad_norm": 59.14422607421875,
      "learning_rate": 9.463106113843993e-05,
      "loss": -6.4698,
      "step": 770
    },
    {
      "epoch": 0.5481377371749825,
      "grad_norm": 68.3644790649414,
      "learning_rate": 9.456078706957133e-05,
      "loss": -6.5819,
      "step": 780
    },
    {
      "epoch": 0.5551651440618411,
      "grad_norm": 72.96343994140625,
      "learning_rate": 9.449754040758961e-05,
      "loss": -6.4701,
      "step": 790
    },
    {
      "epoch": 0.5621925509486999,
      "grad_norm": 47.393516540527344,
      "learning_rate": 9.442726633872103e-05,
      "loss": -6.5356,
      "step": 800
    },
    {
      "epoch": 0.5692199578355587,
      "grad_norm": 99.93370819091797,
      "learning_rate": 9.435699226985243e-05,
      "loss": -6.5243,
      "step": 810
    },
    {
      "epoch": 0.5762473647224174,
      "grad_norm": 168.73931884765625,
      "learning_rate": 9.428671820098383e-05,
      "loss": -6.6569,
      "step": 820
    },
    {
      "epoch": 0.5832747716092762,
      "grad_norm": 50.17271041870117,
      "learning_rate": 9.421644413211526e-05,
      "loss": -6.8741,
      "step": 830
    },
    {
      "epoch": 0.590302178496135,
      "grad_norm": 78.69847869873047,
      "learning_rate": 9.414617006324666e-05,
      "loss": -6.6368,
      "step": 840
    },
    {
      "epoch": 0.5973295853829936,
      "grad_norm": 89.92803192138672,
      "learning_rate": 9.407589599437808e-05,
      "loss": -6.7147,
      "step": 850
    },
    {
      "epoch": 0.6043569922698524,
      "grad_norm": 277.0621337890625,
      "learning_rate": 9.40056219255095e-05,
      "loss": -6.0667,
      "step": 860
    },
    {
      "epoch": 0.6113843991567112,
      "grad_norm": 86.7811508178711,
      "learning_rate": 9.393534785664091e-05,
      "loss": -6.646,
      "step": 870
    },
    {
      "epoch": 0.6184118060435699,
      "grad_norm": 64.3265151977539,
      "learning_rate": 9.386507378777232e-05,
      "loss": -6.1169,
      "step": 880
    },
    {
      "epoch": 0.6254392129304287,
      "grad_norm": 246.79415893554688,
      "learning_rate": 9.379479971890372e-05,
      "loss": -6.7719,
      "step": 890
    },
    {
      "epoch": 0.6324666198172875,
      "grad_norm": 291.45452880859375,
      "learning_rate": 9.372452565003515e-05,
      "loss": -6.7775,
      "step": 900
    },
    {
      "epoch": 0.6394940267041461,
      "grad_norm": 158.0874481201172,
      "learning_rate": 9.365425158116655e-05,
      "loss": -6.8678,
      "step": 910
    },
    {
      "epoch": 0.6465214335910049,
      "grad_norm": 98.92765045166016,
      "learning_rate": 9.358397751229797e-05,
      "loss": -6.6101,
      "step": 920
    },
    {
      "epoch": 0.6535488404778637,
      "grad_norm": 177.81846618652344,
      "learning_rate": 9.351370344342939e-05,
      "loss": -6.7756,
      "step": 930
    },
    {
      "epoch": 0.6605762473647224,
      "grad_norm": 209.10328674316406,
      "learning_rate": 9.344342937456079e-05,
      "loss": -6.7317,
      "step": 940
    },
    {
      "epoch": 0.6676036542515812,
      "grad_norm": 79.2008285522461,
      "learning_rate": 9.33731553056922e-05,
      "loss": -6.856,
      "step": 950
    },
    {
      "epoch": 0.67463106113844,
      "grad_norm": 35.080535888671875,
      "learning_rate": 9.330288123682361e-05,
      "loss": -6.784,
      "step": 960
    },
    {
      "epoch": 0.6816584680252986,
      "grad_norm": 123.33367919921875,
      "learning_rate": 9.323260716795504e-05,
      "loss": -6.8228,
      "step": 970
    },
    {
      "epoch": 0.6886858749121574,
      "grad_norm": 110.54161071777344,
      "learning_rate": 9.316233309908644e-05,
      "loss": -6.8982,
      "step": 980
    },
    {
      "epoch": 0.6957132817990161,
      "grad_norm": 86.40049743652344,
      "learning_rate": 9.309205903021784e-05,
      "loss": -7.0877,
      "step": 990
    },
    {
      "epoch": 0.7027406886858749,
      "grad_norm": 49.513816833496094,
      "learning_rate": 9.302178496134927e-05,
      "loss": -7.0558,
      "step": 1000
    },
    {
      "epoch": 0.7097680955727337,
      "grad_norm": 55.642215728759766,
      "learning_rate": 9.295151089248068e-05,
      "loss": -6.8424,
      "step": 1010
    },
    {
      "epoch": 0.7167955024595924,
      "grad_norm": 65.7772445678711,
      "learning_rate": 9.288123682361209e-05,
      "loss": -6.943,
      "step": 1020
    },
    {
      "epoch": 0.7238229093464511,
      "grad_norm": 68.26837158203125,
      "learning_rate": 9.28109627547435e-05,
      "loss": -6.6938,
      "step": 1030
    },
    {
      "epoch": 0.7308503162333099,
      "grad_norm": 63.334434509277344,
      "learning_rate": 9.274068868587493e-05,
      "loss": -7.1175,
      "step": 1040
    },
    {
      "epoch": 0.7378777231201686,
      "grad_norm": 261.530029296875,
      "learning_rate": 9.267041461700633e-05,
      "loss": -6.9909,
      "step": 1050
    },
    {
      "epoch": 0.7449051300070274,
      "grad_norm": 159.00860595703125,
      "learning_rate": 9.260014054813773e-05,
      "loss": -6.7705,
      "step": 1060
    },
    {
      "epoch": 0.7519325368938862,
      "grad_norm": 91.65581512451172,
      "learning_rate": 9.252986647926916e-05,
      "loss": -6.9613,
      "step": 1070
    },
    {
      "epoch": 0.7589599437807449,
      "grad_norm": 102.63330078125,
      "learning_rate": 9.245959241040056e-05,
      "loss": -7.0755,
      "step": 1080
    },
    {
      "epoch": 0.7659873506676037,
      "grad_norm": 148.8389434814453,
      "learning_rate": 9.238931834153198e-05,
      "loss": -7.1456,
      "step": 1090
    },
    {
      "epoch": 0.7730147575544624,
      "grad_norm": 209.2189178466797,
      "learning_rate": 9.23190442726634e-05,
      "loss": -6.9934,
      "step": 1100
    },
    {
      "epoch": 0.7800421644413211,
      "grad_norm": 120.55187225341797,
      "learning_rate": 9.22487702037948e-05,
      "loss": -6.174,
      "step": 1110
    },
    {
      "epoch": 0.7870695713281799,
      "grad_norm": 129.6073760986328,
      "learning_rate": 9.217849613492622e-05,
      "loss": -6.8899,
      "step": 1120
    },
    {
      "epoch": 0.7940969782150387,
      "grad_norm": 104.16826629638672,
      "learning_rate": 9.210822206605762e-05,
      "loss": -6.9409,
      "step": 1130
    },
    {
      "epoch": 0.8011243851018974,
      "grad_norm": 66.002197265625,
      "learning_rate": 9.203794799718905e-05,
      "loss": -7.2038,
      "step": 1140
    },
    {
      "epoch": 0.8081517919887562,
      "grad_norm": 88.42974853515625,
      "learning_rate": 9.196767392832045e-05,
      "loss": -7.2089,
      "step": 1150
    },
    {
      "epoch": 0.8151791988756149,
      "grad_norm": 219.88674926757812,
      "learning_rate": 9.189739985945187e-05,
      "loss": -7.2009,
      "step": 1160
    },
    {
      "epoch": 0.8222066057624736,
      "grad_norm": 72.87736511230469,
      "learning_rate": 9.182712579058329e-05,
      "loss": -7.2629,
      "step": 1170
    },
    {
      "epoch": 0.8292340126493324,
      "grad_norm": 82.43689727783203,
      "learning_rate": 9.175685172171469e-05,
      "loss": -7.1921,
      "step": 1180
    },
    {
      "epoch": 0.8362614195361912,
      "grad_norm": 59.75246047973633,
      "learning_rate": 9.16865776528461e-05,
      "loss": -7.2145,
      "step": 1190
    },
    {
      "epoch": 0.8432888264230499,
      "grad_norm": 268.36041259765625,
      "learning_rate": 9.161630358397751e-05,
      "loss": -7.0839,
      "step": 1200
    },
    {
      "epoch": 0.8503162333099087,
      "grad_norm": 62.51845932006836,
      "learning_rate": 9.154602951510894e-05,
      "loss": -7.308,
      "step": 1210
    },
    {
      "epoch": 0.8573436401967673,
      "grad_norm": 96.8796157836914,
      "learning_rate": 9.147575544624034e-05,
      "loss": -7.2365,
      "step": 1220
    },
    {
      "epoch": 0.8643710470836261,
      "grad_norm": 63.921627044677734,
      "learning_rate": 9.140548137737174e-05,
      "loss": -7.1622,
      "step": 1230
    },
    {
      "epoch": 0.8713984539704849,
      "grad_norm": 97.95970153808594,
      "learning_rate": 9.133520730850317e-05,
      "loss": -7.3567,
      "step": 1240
    },
    {
      "epoch": 0.8784258608573436,
      "grad_norm": 85.88983154296875,
      "learning_rate": 9.126493323963458e-05,
      "loss": -6.9544,
      "step": 1250
    },
    {
      "epoch": 0.8854532677442024,
      "grad_norm": 231.1924591064453,
      "learning_rate": 9.1194659170766e-05,
      "loss": -7.2324,
      "step": 1260
    },
    {
      "epoch": 0.8924806746310612,
      "grad_norm": 39.58894348144531,
      "learning_rate": 9.11243851018974e-05,
      "loss": -7.4257,
      "step": 1270
    },
    {
      "epoch": 0.8995080815179198,
      "grad_norm": 196.9145965576172,
      "learning_rate": 9.105411103302883e-05,
      "loss": -7.4067,
      "step": 1280
    },
    {
      "epoch": 0.9065354884047786,
      "grad_norm": 72.6319580078125,
      "learning_rate": 9.098383696416023e-05,
      "loss": -7.3203,
      "step": 1290
    },
    {
      "epoch": 0.9135628952916374,
      "grad_norm": 152.64486694335938,
      "learning_rate": 9.091356289529163e-05,
      "loss": -7.3962,
      "step": 1300
    },
    {
      "epoch": 0.9205903021784961,
      "grad_norm": 25.05042266845703,
      "learning_rate": 9.084328882642306e-05,
      "loss": -7.3108,
      "step": 1310
    },
    {
      "epoch": 0.9276177090653549,
      "grad_norm": 151.17747497558594,
      "learning_rate": 9.077301475755447e-05,
      "loss": -7.3855,
      "step": 1320
    },
    {
      "epoch": 0.9346451159522137,
      "grad_norm": 107.43682861328125,
      "learning_rate": 9.070274068868588e-05,
      "loss": -7.4443,
      "step": 1330
    },
    {
      "epoch": 0.9416725228390724,
      "grad_norm": 350.61492919921875,
      "learning_rate": 9.063246661981728e-05,
      "loss": -7.3617,
      "step": 1340
    },
    {
      "epoch": 0.9486999297259311,
      "grad_norm": 83.1407241821289,
      "learning_rate": 9.05621925509487e-05,
      "loss": -7.5029,
      "step": 1350
    },
    {
      "epoch": 0.9557273366127899,
      "grad_norm": 88.5924301147461,
      "learning_rate": 9.049191848208012e-05,
      "loss": -7.1782,
      "step": 1360
    },
    {
      "epoch": 0.9627547434996486,
      "grad_norm": 104.07402038574219,
      "learning_rate": 9.042164441321152e-05,
      "loss": -7.4722,
      "step": 1370
    },
    {
      "epoch": 0.9697821503865074,
      "grad_norm": 79.9546890258789,
      "learning_rate": 9.035137034434295e-05,
      "loss": -7.3738,
      "step": 1380
    },
    {
      "epoch": 0.9768095572733662,
      "grad_norm": 157.92059326171875,
      "learning_rate": 9.028109627547435e-05,
      "loss": -7.5088,
      "step": 1390
    },
    {
      "epoch": 0.9838369641602249,
      "grad_norm": 197.66197204589844,
      "learning_rate": 9.021082220660577e-05,
      "loss": -7.5222,
      "step": 1400
    },
    {
      "epoch": 0.9908643710470836,
      "grad_norm": 66.03207397460938,
      "learning_rate": 9.014054813773719e-05,
      "loss": -7.4772,
      "step": 1410
    },
    {
      "epoch": 0.9978917779339423,
      "grad_norm": 52.583370208740234,
      "learning_rate": 9.007027406886859e-05,
      "loss": -7.5506,
      "step": 1420
    },
    {
      "epoch": 1.0,
      "eval_runtime": 10.4756,
      "eval_samples_per_second": 65428.547,
      "eval_steps_per_second": 16.037,
      "step": 1423
    }
  ],
  "logging_steps": 10,
  "max_steps": 14230,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 549530637172736.0,
  "train_batch_size": 1024,
  "trial_name": null,
  "trial_params": null
}
